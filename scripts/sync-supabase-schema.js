#!/usr/bin/env node

/**
 * Sync Supabase Schema to Markdown
 * 
 * This script connects to your Supabase database and exports the current schema,
 * edge functions, storage buckets, and other metadata to a markdown file for AI reference.
 * 
 * Usage: node scripts/sync-supabase-schema.js
 */

import { createClient } from '@supabase/supabase-js';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Load environment variables
const SUPABASE_URL = process.env.VITE_SUPABASE_URL || 'https://ulmdmzhcdwfadbvfpckt.supabase.co';
const SUPABASE_SERVICE_KEY = process.env.SUPABASE_SERVICE_KEY; // You'll need to add this to .env

if (!SUPABASE_SERVICE_KEY) {
  console.error('‚ùå SUPABASE_SERVICE_KEY not found in environment variables');
  console.log('Add it to your .env file: SUPABASE_SERVICE_KEY=your-service-role-key');
  console.log('Find it in: Supabase Dashboard > Settings > API > Service Role Key');
  process.exit(1);
}

const supabase = createClient(SUPABASE_URL, SUPABASE_SERVICE_KEY);

async function fetchDatabaseSchema() {
  console.log('üìä Fetching database schema...');
  
  const { data: tables, error: tablesError } = await supabase.rpc('get_schema_info');
  
  if (tablesError) {
    // If RPC doesn't exist, query information_schema directly
    const { data, error } = await supabase
      .from('information_schema.tables')
      .select('*')
      .eq('table_schema', 'public')
      .eq('table_type', 'BASE TABLE');
    
    if (error) {
      console.error('Error fetching tables:', error);
      return null;
    }
    return data;
  }
  
  return tables;
}

async function fetchTableColumns(tableName) {
  const { data, error } = await supabase
    .from('information_schema.columns')
    .select('column_name, data_type, is_nullable, column_default, ordinal_position')
    .eq('table_schema', 'public')
    .eq('table_name', tableName)
    .order('ordinal_position');
  
  if (error) {
    console.error(`Error fetching columns for ${tableName}:`, error);
    return [];
  }
  
  return data || [];
}

async function fetchStorageBuckets() {
  console.log('üóÇÔ∏è Fetching storage buckets...');
  
  const { data, error } = await supabase.storage.listBuckets();
  
  if (error) {
    console.error('Error fetching storage buckets:', error);
    return [];
  }
  
  return data || [];
}

async function fetchEdgeFunctions() {
  console.log('‚ö° Fetching edge functions...');
  
  // Edge functions are defined in the file system, not in the database
  const functionsDir = path.join(__dirname, '..', 'supabase', 'functions');
  
  try {
    const functions = await fs.readdir(functionsDir);
    const functionDetails = [];
    
    for (const func of functions) {
      if (func.startsWith('_')) continue; // Skip shared directories
      
      const funcPath = path.join(functionsDir, func, 'index.ts');
      try {
        await fs.access(funcPath);
        functionDetails.push({
          name: func,
          path: `supabase/functions/${func}/index.ts`
        });
      } catch {
        // Function directory exists but no index.ts
      }
    }
    
    return functionDetails;
  } catch (error) {
    console.error('Error reading edge functions:', error);
    return [];
  }
}

async function generateMarkdown(schema) {
  const timestamp = new Date().toISOString();
  
  let markdown = `# Supabase Schema Reference
  
> Last Updated: ${timestamp}
> Project ID: ulmdmzhcdwfadbvfpckt
> URL: ${SUPABASE_URL}

This file is auto-generated by \`scripts/sync-supabase-schema.js\`
Run \`npm run sync:schema\` to update.

## Table of Contents

- [Database Tables](#database-tables)
- [Edge Functions](#edge-functions)
- [Storage Buckets](#storage-buckets)
- [RLS Policies](#rls-policies)

## Database Tables

`;

  // Add tables
  for (const table of schema.tables) {
    markdown += `### ${table.name}\n\n`;
    markdown += `| Column | Type | Nullable | Default |\n`;
    markdown += `|--------|------|----------|----------|\n`;
    
    for (const column of table.columns) {
      markdown += `| ${column.column_name} | ${column.data_type} | ${column.is_nullable} | ${column.column_default || '-'} |\n`;
    }
    markdown += '\n';
  }

  // Add edge functions
  markdown += `## Edge Functions\n\n`;
  markdown += `| Function | Path |\n`;
  markdown += `|----------|------|\n`;
  
  for (const func of schema.edgeFunctions) {
    markdown += `| ${func.name} | \`${func.path}\` |\n`;
  }
  markdown += '\n';

  // Add storage buckets
  markdown += `## Storage Buckets\n\n`;
  markdown += `| Bucket | Public | Size Limit |\n`;
  markdown += `|--------|--------|------------|\n`;
  
  for (const bucket of schema.storageBuckets) {
    markdown += `| ${bucket.name} | ${bucket.public || false} | ${bucket.fileSizeLimit || 'Unlimited'} |\n`;
  }
  markdown += '\n';

  // Add RLS policies summary
  markdown += `## RLS Policies\n\n`;
  markdown += `Tables with Row Level Security enabled:\n\n`;
  
  const tablesWithRLS = schema.tables.filter(t => t.rlsEnabled);
  for (const table of tablesWithRLS) {
    markdown += `- ${table.name}\n`;
  }

  return markdown;
}

async function main() {
  console.log('üöÄ Starting Supabase schema sync...\n');
  
  try {
    // Fetch all tables
    const { data: tables, error: tablesError } = await supabase
      .from('information_schema.tables')
      .select('table_name')
      .eq('table_schema', 'public')
      .eq('table_type', 'BASE TABLE');
    
    if (tablesError) throw tablesError;
    
    const schema = {
      tables: [],
      edgeFunctions: [],
      storageBuckets: []
    };
    
    // Fetch columns for each table
    for (const table of tables || []) {
      const columns = await fetchTableColumns(table.table_name);
      schema.tables.push({
        name: table.table_name,
        columns,
        rlsEnabled: false // Would need another query to check this
      });
    }
    
    // Fetch edge functions
    schema.edgeFunctions = await fetchEdgeFunctions();
    
    // Fetch storage buckets
    schema.storageBuckets = await fetchStorageBuckets();
    
    // Generate markdown
    const markdown = await generateMarkdown(schema);
    
    // Write to file
    const outputPath = path.join(__dirname, '..', 'docs', 'SUPABASE_SCHEMA.md');
    await fs.writeFile(outputPath, markdown, 'utf-8');
    
    console.log(`‚úÖ Schema exported to: docs/SUPABASE_SCHEMA.md`);
    console.log(`üìä Found ${schema.tables.length} tables`);
    console.log(`‚ö° Found ${schema.edgeFunctions.length} edge functions`);
    console.log(`üóÇÔ∏è Found ${schema.storageBuckets.length} storage buckets`);
    
  } catch (error) {
    console.error('‚ùå Error syncing schema:', error);
    process.exit(1);
  }
}

main();